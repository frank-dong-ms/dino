{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "import azureml.core\n",
        "from azureml.core import Workspace, Dataset, Datastore, Experiment, Environment, ScriptRunConfig\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "#from azureml.core.runconfig import PyTorchConfiguration\n",
        "from azureml.core.runconfig import PyTorchConfiguration, DockerConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "from azureml.data import OutputFileDatasetConfig\n",
        "from azureml.telemetry import set_diagnostics_collection\n",
        "\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "set_diagnostics_collection(send_diagnostics=True)\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Turning diagnostics collection on. \nSDK version: 1.38.0\n"
        }
      ],
      "execution_count": 175,
      "metadata": {
        "gather": {
          "logged": 1651045961223
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "azureml._restclient.snapshots_client.SNAPSHOT_MAX_SIZE_BYTES = 6000000000"
      ],
      "outputs": [],
      "execution_count": 176,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651045961366
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_folder = '../dino-large-ori'\n",
        "#os.makedirs(project_folder, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 177,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651045961544
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "datastore = ws.get_default_datastore()\n",
        "dataset = Dataset.get_by_name(ws, name='imagenet_2015_premium_west_europe')\n"
      ],
      "outputs": [],
      "execution_count": 178,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651045963651
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose a name for your cluster\n",
        "cluster_name = 'A100-2'\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing compute target.')\n",
        "except ComputeTargetException:\n",
        "    print('Cannot Find the compute cluster')\n",
        "\n",
        "# use get_status() to get a detailed status for the current AmlCompute. \n",
        "print(compute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing compute target.\n{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2022-04-27T07:36:26.410000+00:00', 'errors': None, 'creationTime': '2022-03-06T10:48:17.444629+00:00', 'modifiedTime': '2022-04-19T01:20:59.825734+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 6, 'nodeIdleTimeBeforeScaleDown': 'PT30S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_ND96AMSR_A100_V4'}\n"
        }
      ],
      "execution_count": 179,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651045964650
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_name = 'dino-A100'\n",
        "experiment = Experiment(ws, name=experiment_name)"
      ],
      "outputs": [],
      "execution_count": 180,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651045965182
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "myenv = Environment(name = \"myenv\")\r\n",
        "myenv.docker.enabled = True\r\n",
        "dockerfile = r\"\"\"\r\n",
        "FROM mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04\r\n",
        "RUN apt-get update && apt-get install -y libgl1-mesa-glx \r\n",
        "RUN echo \"Hello from custom container!\"\r\n",
        "\"\"\"\r\n",
        "myenv.docker.base_image = None\r\n",
        "myenv.docker.base_dockerfile = dockerfile"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "!wget https://github.com/parasailteam/sccl-presynth\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from azureml.core import Environment\r\n",
        "\r\n",
        "#pytorch_env = Environment.from_conda_specification(name='AzureML-PyTorch-1.6-GPU',file_path='distributed-pytorch-with-distributeddataparallel.yml')\r\n",
        "curated_env_name = 'AzureML-pytorch-1.7-ubuntu18.04-py37-cuda11-gpu'\r\n",
        "pytorch_env = Environment.get(workspace=ws, name=curated_env_name)\r\n",
        "pytorch_env.environment_variables = {\"AZUREML_DOWNLOAD_CONCURRENCY\":384} \r\n",
        "\r\n",
        "dino_env = pytorch_env.clone(\"dino_env\")\r\n",
        "\r\n",
        "#conda = CondaDependencies()\r\n",
        "\r\n",
        "# # create environment\r\n",
        "#dino_env.python.conda_dependencies = conda\r\n",
        "docker_config = DockerConfiguration(use_docker=True, arguments = ['--ipc=host'], shm_size='256g')\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "curated_env_name = 'AzureML-pytorch-1.10-ubuntu18.04-py38-cuda11-gpu'\n",
        "pytorch_env = Environment.get(workspace=ws, name=curated_env_name)\n",
        "pytorch_env.environment_variables = {\"AZUREML_DOWNLOAD_CONCURRENCY\":384} \n",
        "\n",
        "dino_env = pytorch_env.clone(\"dino_env\")\n",
        "\n",
        "env = Environment(\"sea-dockerfile\")\n",
        "env.docker.base_image = \"ptebic.azurecr.io/internal/azureml/aifx/stable-ubuntu2004-cu113-py38-torch1102:latest\"\n",
        "env.environment_variables = {\"AZUREML_DOWNLOAD_CONCURRENCY\":384, \"NCCL_TOPO_FILE\": \"/var/run/nvidia-topologyd/A100/virtualTopology.xml\", \"NCCL_SOCKET_IFNAME\": \"eth0\",\"NCCL_IB_GID_INDEX\":3,\"NCCL_IB_TIMEOUT\":20} \n",
        "env.python.user_managed_dependencies = True\n",
        "\n",
        "docker_config = DockerConfiguration(use_docker=True, arguments = ['--ipc=host'] , shm_size='256g')\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = Environment(\"sea-dockerfile\")\r\n",
        "env.docker.base_image = \"ptebic.azurecr.io/test/public/azureml/aifx/stable-ubuntu2004-cu113-py38-torch1110:20220328.v1\"\r\n",
        "env.environment_variables = {\"AZUREML_DOWNLOAD_CONCURRENCY\":384, \"NCCL_TOPO_FILE\": \"/var/run/nvidia-topologyd/A100/virtualTopology.xml\"} \r\n",
        "env.python.user_managed_dependencies = True\r\n",
        "\r\n",
        "docker_config = DockerConfiguration(use_docker=True, arguments = ['--ipc=host'])\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:azureml.core.environment:Property environment_variables is deprecated. Use RunConfiguration.environment_variables to set runtime variables.\n"
        }
      ],
      "execution_count": 181,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651045965300
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patch_size = 16\n",
        "batch_size_per_gpu = 20\n",
        "epochs = 3\n",
        "node_count = 4\n",
        "process_count = 8 * node_count\n",
        "communication_backend = 'NCCL'\n",
        "optimizer = 'fused_adam'"
      ],
      "outputs": [],
      "execution_count": 182,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651045965430
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "unique_string = str(uuid.uuid1())"
      ],
      "outputs": [],
      "execution_count": 183,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651045965565
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder = 'Output_node3'+str(node_count)+'_'+'ViTL_gpus'+str(process_count)+'_bacthsize'+str(batch_size_per_gpu)+'_epochs'+str(epochs)+'_uuid_'+unique_string\n",
        "\n",
        "output= OutputFileDatasetConfig(destination=(datastore, output_folder))"
      ],
      "outputs": [],
      "execution_count": 184,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651045965687
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 185,
          "data": {
            "text/plain": "'Output_node21_ViTL_gpus8_bacthsize20_epochs3_uuid_05db6fa6-c5ff-11ec-bf4b-13cdeaca2de5'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 185,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651045965828
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create distributed config\n",
        "distr_config = PyTorchConfiguration(communication_backend=communication_backend,process_count=process_count, node_count=node_count)\n",
        "# create args\n",
        "args = [\"--arch\", \"vit_large\",\n",
        "        \"--data_path\", dataset.as_mount(), \n",
        "        \"--patch_size\", patch_size,\n",
        "        \"--norm_last_layer\",True, \n",
        "        \"--warmup_teacher_temp\", 0.04, \n",
        "        \"--teacher_temp\", 0.04, \n",
        "        \"--use_fp16\", False, \n",
        "        \"--weight_decay\", 0.04,\n",
        "        \"--weight_decay_end\", 0.08, \n",
        "        \"--clip_grad\", 0, \n",
        "        \"--batch_size_per_gpu\", batch_size_per_gpu, \n",
        "        \"--epochs\", epochs, \n",
        "        \"--freeze_last_layer\", 3, \n",
        "        \"--lr\", 0.0005, \n",
        "        \"--warmup_epochs\", 1, \n",
        "        \"--warmup_teacher_temp_epochs\",1,\n",
        "        \"--min_lr\", 0.0001, \n",
        "        \"--local_crops_number\", 10, \n",
        "        \"--seed\", 0, \n",
        "        \"--num_workers\", 10,\n",
        "        \"--optimizer\", optimizer, \n",
        "        \"--momentum_teacher\", 0.996,\n",
        "        \"--use_bn_in_head\", False, \n",
        "        \"--out_dim\", 65536,\n",
        "        \"--drop_path_rate\", 0.3,\n",
        "        \"--global_crops_scale\", 0.25 , 1.0,\n",
        "        \"--local_crops_scale\",0.05, 0.25,\n",
        "        \"--saveckp_freq\",10, \n",
        "        \"--output_dir\", output.as_mount()]\n",
        "\n",
        "        #ref for 2 nodes from facebook git:{\"arch\": \"vit_small\", \"patch_size\": 16, \"out_dim\": 65536,\n",
        "        # \"norm_last_layer\": false, \"warmup_teacher_temp\": 0.04, \"teacher_temp\": 0.07,\n",
        "        # \"warmup_teacher_temp_epochs\": 30, \"use_fp16\": false, \"weight_decay\": 0.04, \"weight_decay_end\": 0.4, \n",
        "        #\"clip_grad\": 0, \"batch_size_per_gpu\": 64, \"epochs\": 800, \"freeze_last_layer\": 1, \"lr\": 0.0005,\n",
        "        # \"warmup_epochs\": 10, \"min_lr\": 1e-05, \"global_crops_scale\": [0.25, 1.0],\n",
        "        # \"local_crops_scale\": [0.05, 0.25], \"local_crops_number\": 10, \"seed\": 0, \"num_workers\": 10,\n",
        "        # \"world_size\": 16, \"ngpus\": 8, \"nodes\": 2, \"optimizer\": \"adamw\", \"momentum_teacher\": 0.996, \"use_bn_in_head\": false, \"drop_path_rate\": 0.1}\n",
        "\n",
        "        ## ref one node: command: [\"/bin/sh\", \"-c\", \"cd /code; \\ python -m torch.distributed.launch --nproc_per_node=8 main_dino.py \\ --data_path /dataset/imagenet-raw/train --output_dir ./exp_dino/ \\ --freeze_last_layer 1\n",
        "        ## --lr 0.0005 --weight_decay 0.04 --batch_size_per_gpu 64 \\ --drop_path_rate 0.1 --epochs 100 --warmup_epochs 10 \\ \n",
        "        ##--out_dim 65536 --norm_last_layer false --use_bn_in_head false \\ --teacher_temp 0.04 --warmup_teacher_temp 0.04\n",
        "        ## --warmup_teacher_temp_epochs 0 \\ --use_fp16 false --clip_grad 3.0 \\ --momentum_teacher 0.996\n",
        "        ## \\ --global_crops_scale 0.25 1 --local_crops_scale 0.05 0.25 \\ --local_crops_number 6 \"]\n",
        "\n",
        "print(args)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['--arch', 'vit_large', '--data_path', <azureml.data.dataset_consumption_config.DatasetConsumptionConfig object at 0x7f16740d2790>, '--patch_size', 16, '--norm_last_layer', True, '--warmup_teacher_temp', 0.04, '--teacher_temp', 0.04, '--use_fp16', False, '--weight_decay', 0.04, '--weight_decay_end', 0.08, '--clip_grad', 0, '--batch_size_per_gpu', 20, '--epochs', 3, '--freeze_last_layer', 3, '--lr', 0.0005, '--warmup_epochs', 1, '--warmup_teacher_temp_epochs', 1, '--min_lr', 0.0001, '--local_crops_number', 10, '--seed', 0, '--num_workers', 10, '--optimizer', 'fused_adam', '--momentum_teacher', 0.996, '--use_bn_in_head', False, '--out_dim', 65536, '--drop_path_rate', 0.3, '--global_crops_scale', 0.25, 1.0, '--local_crops_scale', 0.05, 0.25, '--saveckp_freq', 10, '--output_dir', <azureml.data.output_dataset_config.OutputFileDatasetConfig object at 0x7f1687900520>]\n"
        }
      ],
      "execution_count": 186,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651045965958
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src = ScriptRunConfig(source_directory=project_folder,                    \n",
        "                      script='main_dino.py',\n",
        "                       arguments=args,\n",
        "                       compute_target=compute_target,\n",
        "                       environment=env ,\n",
        "                       distributed_job_config=distr_config,\n",
        "                       docker_runtime_config=docker_config\n",
        "                    )\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:root:You might see network latency and increased data transfer costs if you chose a cluster in a location different from the location of your workspace\n"
        }
      ],
      "execution_count": 187,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651045966089
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = experiment.submit(src)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Submitting /mnt/batch/tasks/shared/LS_root/mounts/clusters/frdong2/code/Users/frdong/dino-vit-large directory for run. The size of the directory >= 25 MB, so it can take a few minutes.\n"
        }
      ],
      "execution_count": 188,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651045989109
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run.tag(\"author\",\"frdong\")\n",
        "run.tag(\"storage\" , \"premium\")\n",
        "run.tag(\"envoirnment\" ,'ENV with Adamw Optimizer' )\n",
        "run.tag(\"dataset\", \"download\")\n",
        "run.tag(\"batch_size_per_gpu\" , str(batch_size_per_gpu))\n",
        "run.tag(\"patch_size\" , str(patch_size))\n",
        "run.tag(\"epochs\" , str(epochs))\n",
        "run.tag(\"communication_backend\" , str(communication_backend))\n",
        "run.tag(\"gpus\" , str(process_count))\n",
        "run.tag(\"nodes\" , str(node_count))\n",
        "run.tag(\"comments\",\"4 nodes 2 epochs, 20 per gpus with profile info\")\n"
      ],
      "outputs": [],
      "execution_count": 189,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651045993117
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(run)\n",
        "#RunDetails(run).show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run(Experiment: dino-A100,\nId: dino-A100_1651045964_d2c51ec8,\nType: azureml.scriptrun,\nStatus: Queued)\n"
        }
      ],
      "execution_count": 190,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651045993264
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}